run_name: qwen2-0.5b-it-dapo-baseline
output_dir: ./outputs/qwen2-0.5b-it-dapo-baseline
model_id: "Qwen/Qwen2-0.5B-Instruct"
attn_implementation: sdpa # eager, flash_attention_2
torch_dtype: bfloat16

wandb_project: dapo
wandb_entity: artificial-intelligence-research

# Dataset config
dataset_name: openai/gsm8k

# Training arguments
use_vllm: true
loss_type: bnpo
epsilon: 0.2
epsilon_high: null # 0.28
beta: 0.0 # KL divergence coefficient
mask_truncated_completions: true # overlong filtering
use_soft_overlong_punishment: false # true
soft_punish_cache: 256
use_dynamic_sampling: false # true
learning_rate: 5e-6
adam_beta1: 0.9
adam_beta2: 0.99
weight_decay: 0.1
warmup_ratio: 0.1
lr_scheduler_type: cosine
optim: adamw_torch_fused
ddp_find_unused_parameters: false
logging_steps: 1
per_device_train_batch_size: 4
gradient_accumulation_steps: 1 # Increase to 4 for smoother training
num_generations: 4 # Decrease if out of memory
max_prompt_length: 256
max_completion_length: 768 # 1024 - 256
max_steps: 250
save_steps: 50
max_grad_norm: 0.1
bf16: true
report_to: wandb
seed: 3407
